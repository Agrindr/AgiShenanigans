import cv2
import mediapipe as mp

# Initialize Mediapipe Hand Detector and Face Mesh
mp_hands = mp.solutions.hands
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.7)

# Start the webcam
cap = cv2.VideoCapture(0)

def draw_square_and_display_coordinates(img, x, y, w, h):
    # Draw a square
    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
    # Display the coordinates
    text = f"X: {x}, Y: {y}"
    cv2.putText(img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

def is_fist(hand_landmarks):
    """
    Detect if a hand gesture is a fist based on landmark positions.
    """
    try:
        wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
        finger_tips = [
            hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP],
            hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_TIP],
            hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_TIP],
            hand_landmarks.landmark[mp_hands.HandLandmark.RING_TIP],
            hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP],
        ]
        # Check if all fingertips are below the wrist (greater y-coordinate in image space)
        return all(finger_tip.y > wrist.y for finger_tip in finger_tips)
    except (AttributeError, ValueError) as e:
        print(f"Error in fist detection: {e}")
        return False

def is_smiling(face_landmarks, frame_shape):
    """
    Detect if the face is smiling based on mouth landmarks.
    """
    try:
        # Convert normalized landmarks to pixel coordinates
        def to_pixel(landmark):
            return int(landmark.x * frame_shape[1]), int(landmark.y * frame_shape[0])

        # Get key landmarks for the mouth
        upper_lip = face_landmarks.landmark[13]  # Upper lip
        lower_lip = face_landmarks.landmark[14]  # Lower lip
        left_mouth_corner = face_landmarks.landmark[78]  # Left corner of the mouth
        right_mouth_corner = face_landmarks.landmark[308]  # Right corner of the mouth

        # Calculate distances
        lip_distance = abs(lower_lip.y - upper_lip.y)
        mouth_width = abs(left_mouth_corner.x - right_mouth_corner.x)

        # Threshold for smiling (adjust as necessary)
        return lip_distance / mouth_width > 0.2
    except Exception as e:
        print(f"Error in smile detection: {e}")
        return False

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("Failed to grab frame. Exiting.")
        break

    # Flip the frame for a mirror effect
    frame = cv2.flip(frame, 1)

    # Convert the frame to RGB for Mediapipe processing
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Process hands and face mesh
    hand_results = hands.process(rgb_frame)
    face_mesh_results = face_mesh.process(rgb_frame)

    # Hand detection
    if hand_results.multi_hand_landmarks:
        for hand_landmarks in hand_results.multi_hand_landmarks:
            try:
                # Get the bounding box for the hand
                x_min = int(min([lm.x for lm in hand_landmarks.landmark]) * frame.shape[1])
                y_min = int(min([lm.y for lm in hand_landmarks.landmark]) * frame.shape[0])
                x_max = int(max([lm.x for lm in hand_landmarks.landmark]) * frame.shape[1])
                y_max = int(max([lm.y for lm in hand_landmarks.landmark]) * frame.shape[0])

                # Calculate the width and height of the bounding box
                w = x_max - x_min
                h = y_max - y_min

                # Draw the square and display the coordinates
                draw_square_and_display_coordinates(frame, x_min, y_min, w, h)

                # Detect fist gesture
                if is_fist(hand_landmarks):
                    cv2.putText(frame, "You are making a fist!", (x_min, y_min - 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                    print("You are making a fist!")

                # Draw landmarks and connections on the hand
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            except Exception as e:
                print(f"Error processing hand landmarks: {e}")

    # Face mesh detection
    if face_mesh_results.multi_face_landmarks:
        for face_landmarks in face_mesh_results.multi_face_landmarks:
            try:
                # Check for smile
                if is_smiling(face_landmarks, frame.shape):
                    cv2.putText(frame, "You smiled!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
                    print("You smiled!")

                # Draw landmarks and connections for the face
                mp_drawing.draw_landmarks(
                    frame,
                    face_landmarks,
                    mp_face_mesh.FACEMESH_TESSELATION,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()
                )
                mp_drawing.draw_landmarks(
                    frame,
                    face_landmarks,
                    mp_face_mesh.FACEMESH_CONTOURS,
                    landmark_drawing_spec=None,
                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()
                )
            except Exception as e:
                print(f"Error processing face landmarks: {e}")

    # Display the frame
    cv2.imshow('Hand and Face Mesh Detection', frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
